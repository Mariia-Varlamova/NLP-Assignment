{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, AdamW, AutoTokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "RS = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if device == torch.device('cpu'):\n",
    "    print('Using cpu')\n",
    "else:\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "    print('Using {} GPUs'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lhZq2N964W1K"
   },
   "outputs": [],
   "source": [
    "# links to training and test samples\n",
    "url_train = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/train.csv\"\n",
    "url_test = \"https://raw.githubusercontent.com/PolyAI-LDN/task-specific-datasets/master/banking_data/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df_train = pd.read_csv(url_train)\n",
    "df_test = pd.read_csv(url_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am still waiting on my card?</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What can I do if my card still hasn't arrived ...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been waiting over a week. Is the card s...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can I track my card while it is in the process...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I know if I will get my card, or if it ...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      category\n",
       "0                     I am still waiting on my card?  card_arrival\n",
       "1  What can I do if my card still hasn't arrived ...  card_arrival\n",
       "2  I have been waiting over a week. Is the card s...  card_arrival\n",
       "3  Can I track my card while it is in the process...  card_arrival\n",
       "4  How do I know if I will get my card, or if it ...  card_arrival"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the data\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10003 entries, 0 to 10002\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      10003 non-null  object\n",
      " 1   category  10003 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 156.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information about features\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       0.00\n",
       "category   0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring gaps in a dataset\n",
    "df_train.isna().mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicates\n",
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for analysis categorical features\n",
    "def unique(colomns, data):\n",
    "    for column in colomns:\n",
    "        print(f'Number of unique values ​​in a column {column}: {data[column].nunique()}')\n",
    "        print(data[column].unique())\n",
    "        print('-----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values ​​in a column category: 77\n",
      "['card_arrival' 'card_linking' 'exchange_rate'\n",
      " 'card_payment_wrong_exchange_rate' 'extra_charge_on_statement'\n",
      " 'pending_cash_withdrawal' 'fiat_currency_support'\n",
      " 'card_delivery_estimate' 'automatic_top_up' 'card_not_working'\n",
      " 'exchange_via_app' 'lost_or_stolen_card' 'age_limit' 'pin_blocked'\n",
      " 'contactless_not_working' 'top_up_by_bank_transfer_charge'\n",
      " 'pending_top_up' 'cancel_transfer' 'top_up_limits'\n",
      " 'wrong_amount_of_cash_received' 'card_payment_fee_charged'\n",
      " 'transfer_not_received_by_recipient' 'supported_cards_and_currencies'\n",
      " 'getting_virtual_card' 'card_acceptance' 'top_up_reverted'\n",
      " 'balance_not_updated_after_cheque_or_cash_deposit'\n",
      " 'card_payment_not_recognised' 'edit_personal_details'\n",
      " 'why_verify_identity' 'unable_to_verify_identity' 'get_physical_card'\n",
      " 'visa_or_mastercard' 'topping_up_by_card' 'disposable_card_limits'\n",
      " 'compromised_card' 'atm_support' 'direct_debit_payment_not_recognised'\n",
      " 'passcode_forgotten' 'declined_cash_withdrawal' 'pending_card_payment'\n",
      " 'lost_or_stolen_phone' 'request_refund' 'declined_transfer'\n",
      " 'Refund_not_showing_up' 'declined_card_payment' 'pending_transfer'\n",
      " 'terminate_account' 'card_swallowed' 'transaction_charged_twice'\n",
      " 'verify_source_of_funds' 'transfer_timing' 'reverted_card_payment?'\n",
      " 'change_pin' 'beneficiary_not_allowed' 'transfer_fee_charged'\n",
      " 'receiving_money' 'failed_transfer' 'transfer_into_account'\n",
      " 'verify_top_up' 'getting_spare_card' 'top_up_by_cash_or_cheque'\n",
      " 'order_physical_card' 'virtual_card_not_working'\n",
      " 'wrong_exchange_rate_for_cash_withdrawal' 'get_disposable_virtual_card'\n",
      " 'top_up_failed' 'balance_not_updated_after_bank_transfer'\n",
      " 'cash_withdrawal_not_recognised' 'exchange_charge'\n",
      " 'top_up_by_card_charge' 'activate_my_card' 'cash_withdrawal_charge'\n",
      " 'card_about_to_expire' 'apple_pay_or_google_pay' 'verify_my_identity'\n",
      " 'country_support']\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's check the correctness of the toxic column category\n",
    "unique(['category'], df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze how many records we have for each category\n",
    "category_counts = df_train['category'].value_counts()\n",
    "\n",
    "# Create a table with the number of records and the percentage of the total\n",
    "category_table = pd.DataFrame({\n",
    "    'Count': category_counts,\n",
    "    'Percentage': (category_counts / category_counts.sum() * 100).round(2) \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Count  Percentage\n",
      "category                                                           \n",
      "card_payment_fee_charged                            187        1.87\n",
      "direct_debit_payment_not_recognised                 182        1.82\n",
      "balance_not_updated_after_cheque_or_cash_deposit    181        1.81\n",
      "wrong_amount_of_cash_received                       180        1.80\n",
      "cash_withdrawal_charge                              177        1.77\n",
      "transaction_charged_twice                           175        1.75\n",
      "declined_cash_withdrawal                            173        1.73\n",
      "transfer_fee_charged                                172        1.72\n",
      "transfer_not_received_by_recipient                  171        1.71\n",
      "balance_not_updated_after_bank_transfer             171        1.71\n",
      "request_refund                                      169        1.69\n",
      "card_payment_not_recognised                         168        1.68\n",
      "card_payment_wrong_exchange_rate                    167        1.67\n",
      "extra_charge_on_statement                           166        1.66\n",
      "wrong_exchange_rate_for_cash_withdrawal             163        1.63\n",
      "Refund_not_showing_up                               162        1.62\n",
      "reverted_card_payment?                              161        1.61\n",
      "cash_withdrawal_not_recognised                      160        1.60\n",
      "activate_my_card                                    159        1.59\n",
      "pending_card_payment                                159        1.59\n",
      "cancel_transfer                                     157        1.57\n",
      "beneficiary_not_allowed                             156        1.56\n",
      "declined_card_payment                               153        1.53\n",
      "card_arrival                                        153        1.53\n",
      "pending_top_up                                      149        1.49\n",
      "pending_transfer                                    148        1.48\n",
      "top_up_reverted                                     146        1.46\n",
      "top_up_failed                                       145        1.45\n",
      "pending_cash_withdrawal                             143        1.43\n",
      "card_linking                                        139        1.39\n",
      "failed_transfer                                     137        1.37\n",
      "visa_or_mastercard                                  135        1.35\n",
      "declined_transfer                                   133        1.33\n",
      "getting_spare_card                                  129        1.29\n",
      "card_about_to_expire                                129        1.29\n",
      "country_support                                     129        1.29\n",
      "supported_cards_and_currencies                      129        1.29\n",
      "transfer_timing                                     128        1.28\n",
      "automatic_top_up                                    127        1.27\n",
      "fiat_currency_support                               126        1.26\n",
      "verify_top_up                                       126        1.26\n",
      "apple_pay_or_google_pay                             126        1.26\n",
      "change_pin                                          122        1.22\n",
      "lost_or_stolen_phone                                121        1.21\n",
      "why_verify_identity                                 121        1.21\n",
      "edit_personal_details                               121        1.21\n",
      "disposable_card_limits                              121        1.21\n",
      "exchange_charge                                     121        1.21\n",
      "order_physical_card                                 120        1.20\n",
      "exchange_via_app                                    118        1.18\n",
      "pin_blocked                                         115        1.15\n",
      "top_up_by_cash_or_cheque                            114        1.14\n",
      "top_up_by_card_charge                               114        1.14\n",
      "transfer_into_account                               113        1.13\n",
      "verify_source_of_funds                              113        1.13\n",
      "exchange_rate                                       112        1.12\n",
      "card_delivery_estimate                              112        1.12\n",
      "card_not_working                                    112        1.12\n",
      "top_up_by_bank_transfer_charge                      111        1.11\n",
      "age_limit                                           110        1.10\n",
      "terminate_account                                   108        1.08\n",
      "get_physical_card                                   106        1.06\n",
      "passcode_forgotten                                  105        1.05\n",
      "verify_my_identity                                  104        1.04\n",
      "topping_up_by_card                                  103        1.03\n",
      "unable_to_verify_identity                           102        1.02\n",
      "getting_virtual_card                                 98        0.98\n",
      "get_disposable_virtual_card                          97        0.97\n",
      "top_up_limits                                        97        0.97\n",
      "receiving_money                                      95        0.95\n",
      "atm_support                                          87        0.87\n",
      "compromised_card                                     86        0.86\n",
      "lost_or_stolen_card                                  82        0.82\n",
      "card_swallowed                                       61        0.61\n",
      "card_acceptance                                      59        0.59\n",
      "virtual_card_not_working                             41        0.41\n",
      "contactless_not_working                              35        0.35\n"
     ]
    }
   ],
   "source": [
    "print(category_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are not balanced, balancing is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I locate my card?</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I still have not received my new card, I order...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I ordered a card but it has not arrived. Help ...</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is there a way to know when my card will arrive?</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My card has not arrived yet.</td>\n",
       "      <td>card_arrival</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text      category\n",
       "0                           How do I locate my card?  card_arrival\n",
       "1  I still have not received my new card, I order...  card_arrival\n",
       "2  I ordered a card but it has not arrived. Help ...  card_arrival\n",
       "3   Is there a way to know when my card will arrive?  card_arrival\n",
       "4                       My card has not arrived yet.  card_arrival"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the data\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS-тег \n",
    "def get_wordnet_pos(word: str) -> str:\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    lemm_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
    "    lemm_text = \" \".join(lemm_words)\n",
    "    cleared_text = re.sub(r'[^a-zA-Z\\s]', '', lemm_text) \n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10003/10003 [00:51<00:00, 195.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          i be still wait on my card \n",
      "1    what can i do if my card still have nt arrive ...\n",
      "2    i have be wait over a week  be the card still ...\n",
      "Name: lemm_text, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['lemm_text'] = df_train['text'].progress_apply(lemmatize)\n",
    "print(df_train['lemm_text'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8036</th>\n",
       "      <td>top_up_by_cash_or_cheque</td>\n",
       "      <td>i try to deposit a cheque into my account and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category                                          lemm_text\n",
       "8036  top_up_by_cash_or_cheque  i try to deposit a cheque into my account and ..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train =df_train.drop(['text'], axis=1)\n",
    "df_train.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_train['lemm_text'].values \n",
    "\n",
    "features = [\"[CLS] \" + feature + \" [SEP]\" for feature in features]\n",
    "\n",
    "target = df_train['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['card_arrival', 'card_arrival', 'card_arrival', ...,\n",
       "       'country_support', 'country_support', 'country_support'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "target = label_encoder.fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10003, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sample size:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3080, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Training sample size:')\n",
    "display(df_train.shape)\n",
    "\n",
    "print(f'Test sample size:')\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'be', 'still', 'wait', 'on', 'my', 'card', '[SEP]']\n",
      "CPU times: total: 1.69 s\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(i) for i in features]\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 155\n",
    "BATCH_SIZE = 16\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x[:150]) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(\n",
    "    input_ids,\n",
    "    maxlen = MAX_LEN,\n",
    "    dtype = \"long\",\n",
    "    truncating = \"post\",\n",
    "    padding = \"post\"\n",
    ")\n",
    "attention_masks = [[float(i > 0) for i in seq] for seq in input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, target, \n",
    "                                                                                    random_state=RS, test_size=0.1)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=RS, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Вычисляем веса классов\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced', \n",
    "    classes=np.unique(target), \n",
    "    y=target\n",
    ")\n",
    "\n",
    "# Вычисляем веса для каждого примера\n",
    "sample_weights = [class_weights[label] for label in train_labels]\n",
    "\n",
    "# Создаем WeightedRandomSampler\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler = sampler,\n",
    "    batch_size = BATCH_SIZE \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data,\n",
    "    sampler = SequentialSampler(validation_data),\n",
    "    batch_size = BATCH_SIZE \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=77, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=77)\n",
    "model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on train sample: 3.85794\n",
      "Percentage of correct predictions on the validation set: 48.25%\n",
      "CPU times: total: 5h 16min 59s\n",
      "Wall time: 1h 4min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids = torch. tensor(b_input_ids). to (torch. int64)\n",
    "    b_labels = b_labels.to(torch.long)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    loss[0].backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "print(\"Loss on train sample: {0:.5f}\".format(train_loss / len(train_dataloader)))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in validation_dataloader:   \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids = torch. tensor(b_input_ids). to (torch. int64)\n",
    "    b_labels = b_labels.to(torch.long)\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids = None, attention_mask = b_input_mask)\n",
    "\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "    batch_labels = np.array(label_ids)     \n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Percentage of correct predictions on the validation set: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_BERT = round(f1_score(valid_labels, valid_preds, average='macro'), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_score BERT: 0.46\n"
     ]
    }
   ],
   "source": [
    "print(\"F1_score BERT: {0:.2f}\".format(f1_score(valid_labels, valid_preds, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
